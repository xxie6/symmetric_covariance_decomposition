---
title: "symebcovmf_tree_exploration"
author: "Annie Xie"
date: "2025-04-15"
output: 
  workflowr::wflow_html:
    code_folding: hide
editor_options:
  chunk_output_type: console
---

# Introduction
In this example, we further explore symEBcovMF on tree data.

# Packages and Functions

```{r}
library(ebnm)
library(pheatmap)
library(ggplot2)
```

```{r}
source('code/visualization_functions.R')
source('code/symebcovmf_functions.R')
```

# Data Generation

```{r}
sim_4pops <- function(args) {
  set.seed(args$seed)
  
  n <- sum(args$pop_sizes)
  p <- args$n_genes
  
  FF <- matrix(rnorm(7 * p, sd = rep(args$branch_sds, each = p)), ncol = 7)
  # if (args$constrain_F) {
  #   FF_svd <- svd(FF)
  #   FF <- FF_svd$u
  #   FF <- t(t(FF) * branch_sds * sqrt(p))
  # }
  
  LL <- matrix(0, nrow = n, ncol = 7)
  LL[, 1] <- 1
  LL[, 2] <- rep(c(1, 1, 0, 0), times = args$pop_sizes)
  LL[, 3] <- rep(c(0, 0, 1, 1), times = args$pop_sizes)
  LL[, 4] <- rep(c(1, 0, 0, 0), times = args$pop_sizes)
  LL[, 5] <- rep(c(0, 1, 0, 0), times = args$pop_sizes)
  LL[, 6] <- rep(c(0, 0, 1, 0), times = args$pop_sizes)
  LL[, 7] <- rep(c(0, 0, 0, 1), times = args$pop_sizes)
  
  E <- matrix(rnorm(n * p, sd = args$indiv_sd), nrow = n)
  Y <- LL %*% t(FF) + E
  YYt <- (1/p)*tcrossprod(Y)
  return(list(Y = Y, YYt = YYt, LL = LL, FF = FF, K = ncol(LL)))
}
```

```{r}
sim_args = list(pop_sizes = rep(40, 4), n_genes = 1000, branch_sds = rep(2,7), indiv_sd = 1, seed = 1)
sim_data <- sim_4pops(sim_args)
```

This is a heatmap of the scaled Gram matrix:
```{r}
plot_heatmap(sim_data$YYt, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(sim_data$YYt)), max(abs(sim_data$YYt)), length.out = 50))
```

This is a scatter plot of the true loadings matrix:
```{r}
pop_vec <- c(rep('A', 40), rep('B', 40), rep('C', 40), rep('D', 40))
plot_loadings(sim_data$LL, pop_vec)
```

This is a plot of the eigenvalues of the Gram matrix:
```{r}
S_eigen <- eigen(sim_data$YYt)
plot(S_eigen$values) + abline(a = 0, b = 0, col = 'red')
```

This is the minimum eigenvalue:
```{r}
min(S_eigen$values)
```

# symEBcovMF Set Up

I am particularly interested in when the fourth factor is fit. So I will start by fitting three factors.

```{r}
symebcovmf_exp_init_fit <- sym_ebcovmf_fit(S = sim_data$YYt, ebnm_fn = ebnm::ebnm_point_exponential, K = 3, maxiter = 500, rank_one_tol = 10^(-8), tol = 10^(-8), refit_lam = TRUE)
```

```{r}
symebcovmf_gb_init_fit <- sym_ebcovmf_fit(S = sim_data$YYt, ebnm_fn = ebnm::ebnm_generalized_binary, K = 3, maxiter = 500, rank_one_tol = 10^(-8), tol = 10^(-8), refit_lam = TRUE)
```

This is a scatter plot of $\hat{L}_{exp}$, the estimate from symEBcovMF with point-exp prior:
```{r}
bal_pops <- c(rep('A', 40), rep('B', 40), rep('C', 40), rep('D', 40))
plot_loadings(symebcovmf_exp_init_fit$L_pm %*% diag(sqrt(symebcovmf_exp_init_fit$lambda)), bal_pops)
```

This is a scatter plot of $\hat{L}_{gb}$, the estimate from symEBcovMF with gb prior:
```{r}
plot_loadings(symebcovmf_gb_init_fit$L_pm %*% diag(sqrt(symebcovmf_gb_init_fit$lambda)), bal_pops)
```

This is a plot of the eigenvalues of the residual matrix for point-exp prior:
```{r}
resid_exp_eigen <- eigen(sim_data$YYt - tcrossprod(symebcovmf_exp_init_fit$L_pm %*% diag(sqrt(symebcovmf_exp_init_fit$lambda), ncol = 1)))
plot(resid_exp_eigen$values) + abline(h=0, col = 'red')
```

```{r}
min(resid_exp_eigen$values)
```

This is a plot of the eigenvalues of the residual matrix for gb prior:
```{r}
resid_gb_eigen <- eigen(sim_data$YYt - tcrossprod(symebcovmf_gb_init_fit$L_pm %*% diag(sqrt(symebcovmf_gb_init_fit$lambda), ncol = 1)))
plot(resid_gb_eigen$values) + abline(h=0, col = 'red')
```

```{r}
min(resid_gb_eigen$values)
```

# Fitting the fourth factor

## Point-exponential prior
```{r}
symebcovmf_exp_fit <- sym_ebcovmf_r1_fit(sim_data$YYt, symebcovmf_exp_init_fit, ebnm_fn = ebnm::ebnm_point_exponential, maxiter = 500, tol = 10^(-8))
symebcovmf_exp_fit <- refit_lambda(sim_data$YYt, symebcovmf_exp_fit)
```

### Visualization of Estimate
```{r}
plot(symebcovmf_exp_fit$L_pm[,4])
```

### Visualization of ELBO

This is a plot of the progression of the ELBO:
```{r}
idx <- which(symebcovmf_exp_fit$vec_elbo_full == 4)
plot(symebcovmf_exp_fit$vec_elbo_full[-c(1:idx)], type = 'b', xlab = 'Iter', ylab = 'ELBO') 
```

### Progression of Estimate
```{r}
R_exp <- sim_data$YYt - tcrossprod(symebcovmf_exp_init_fit$L_pm %*% diag(sqrt(symebcovmf_exp_init_fit$lambda), ncol = 3))
estimates_exp_list <- list(sym_ebcovmf_r1_init(R_exp)$v)
for (i in 1:13){
  estimates_exp_list[[(i+1)]] <- sym_ebcovmf_r1_fit(sim_data$YYt, symebcovmf_exp_init_fit, ebnm_fn = ebnm::ebnm_point_exponential, maxiter = i, tol = 10^(-8))$L_pm[,4]
}
```

```{r}
par(mfrow = c(7,2), mar = c(2, 2, 1, 1) + 0.1)
for (i in 1:14){
  plot(estimates_exp_list[[i]], main = paste('Iter', (i-1)), ylab = 'L')
}
par(mfrow = c(1,1))
```

```{r}
plot_heatmap(R_exp, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(R_exp)), max(abs(R_exp)), length.out = 50))
```

## Generalized binary prior
```{r}
symebcovmf_gb_fit <- sym_ebcovmf_r1_fit(sim_data$YYt, symebcovmf_gb_init_fit, ebnm_fn = ebnm::ebnm_generalized_binary, maxiter = 500, tol = 10^(-8))
symebcovmf_gb_fit <- refit_lambda(sim_data$YYt, symebcovmf_gb_fit)
```

### Visualization of Estimate
```{r}
plot(symebcovmf_gb_fit$L_pm[,4])
```

### Visualization of ELBO

This is a plot of the progression of the ELBO:
```{r}
idx <- which(symebcovmf_gb_fit$vec_elbo_full == 4)
plot(symebcovmf_gb_fit$vec_elbo_full[-c(1:idx)], type = 'b', xlab = 'Iter', ylab = 'ELBO') 
```

### Progression of Estimate
```{r}
R_gb <- sim_data$YYt - tcrossprod(symebcovmf_gb_init_fit$L_pm %*% diag(sqrt(symebcovmf_gb_init_fit$lambda), ncol = 3))
estimates_gb_list <- list(sym_ebcovmf_r1_init(R_gb)$v)
for (i in 1:11){
  estimates_gb_list[[(i+1)]] <- sym_ebcovmf_r1_fit(sim_data$YYt, symebcovmf_gb_init_fit, ebnm_fn = ebnm::ebnm_generalized_binary, maxiter = i, tol = 10^(-8))$L_pm[,4]
}
```

```{r}
par(mfrow = c(6,2), mar = c(2, 2, 1, 1) + 0.1)
max_y <- max(sapply(estimates_gb_list, max))
min_y <- min(sapply(estimates_gb_list, min))
for (i in 1:12){
  plot(estimates_gb_list[[i]], main = paste('Iter', (i-1)), ylab = 'L', ylim = c(min_y, max_y))
}
par(mfrow = c(1,1))
```


```{r}
plot_heatmap(R_gb, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(R_gb)), max(abs(R_gb)), length.out = 50))
```

## Observations
We can see that point-exponential prior is able to find a sparser solution in this setting. On the other hand, the generalized binary prior found a less sparse, binary solution. Something to try in the future: if I initialize the generalized-binary prior fit with the correct factor, will it recover something close to the correct factor? General question: how sensitive is the generalized binary prior to initialization? My guess is it would be pretty sensitive.

# Mixing point-exponential and generalized binary
I want to try fitting the fourth factor with a point-exponential prior, but using the generalized-binary fit for the first three factors. I'm interested in this because I am interested in developing an procedure that uses the point-exponential prior as an initialization, and then refines the fit with a binary or generalized-binary prior.

## Point-exponential prior 
```{r}
symebcovmf_exp_gb_fit <- sym_ebcovmf_r1_fit(sim_data$YYt, symebcovmf_gb_init_fit, ebnm_fn = ebnm::ebnm_point_exponential, maxiter = 500, tol = 10^(-8))
symebcovmf_exp_gb_fit <- refit_lambda(sim_data$YYt, symebcovmf_exp_gb_fit)
```

### Visualization of Estimate
```{r}
plot(symebcovmf_exp_gb_fit$L_pm[,4])
```

### Visualization of ELBO

This is a plot of the progression of the ELBO:
```{r}
idx <- which(symebcovmf_exp_gb_fit$vec_elbo_full == 4)
plot(symebcovmf_exp_gb_fit$vec_elbo_full[-c(1:idx)], type = 'b', xlab = 'Iter', ylab = 'ELBO') 
```

### Progression of Estimate
```{r}
#R_gb <- sim_data$YYt - tcrossprod(symebcovmf_gb_init_fit$L_pm %*% diag(sqrt(symebcovmf_gb_init_fit$lambda), ncol = 3))
estimates_exp_gb_list <- list(sym_ebcovmf_r1_init(R_gb)$v)
for (i in 1:13){
  estimates_exp_gb_list[[(i+1)]] <- sym_ebcovmf_r1_fit(sim_data$YYt, symebcovmf_gb_init_fit, ebnm_fn = ebnm::ebnm_point_exponential, maxiter = i, tol = 10^(-8))$L_pm[,4]
}
```

```{r}
par(mfrow = c(7,2), mar = c(2, 2, 1, 1) + 0.1)
for (i in 1:14){
  plot(estimates_exp_gb_list[[i]], main = paste('Iter', (i-1)), ylab = 'L')
}
par(mfrow = c(1,1))
```

### Observations
Using the point-exponential prior to fit the fourth factor from the generalized-binary fit, we see that the fourth factor does not capture a singular population effect. Instead, it captures two populations. This suggests that the point-exponential prior alone may not be enough to get a sparse solution. Looking at the residual matrices and the eigenvalues, it looks like there is better separation between the first and second eigenvalue of the residual matrix from the point-exponential fit compared to that of the generalized-binary fit. Therefore, that may make it easier for the method to find only one population effect as a factor vs. grouping together effects. 

## Generalized binary prior 
```{r}
symebcovmf_gb_exp_fit <- sym_ebcovmf_r1_fit(sim_data$YYt, symebcovmf_exp_init_fit, ebnm_fn = ebnm::ebnm_generalized_binary, maxiter = 500, tol = 10^(-8))
symebcovmf_gb_exp_fit <- refit_lambda(sim_data$YYt, symebcovmf_gb_exp_fit)
```

### Visualization of Estimate
```{r}
plot(symebcovmf_gb_exp_fit$L_pm[,4])
```

### Visualization of ELBO

This is a plot of the progression of the ELBO:
```{r}
idx <- which(symebcovmf_gb_exp_fit$vec_elbo_full == 4)
plot(symebcovmf_gb_exp_fit$vec_elbo_full[-c(1:idx)], type = 'b', xlab = 'Iter', ylab = 'ELBO') 
```

### Progression of Estimate
```{r}
#R_gb <- sim_data$YYt - tcrossprod(symebcovmf_gb_init_fit$L_pm %*% diag(sqrt(symebcovmf_gb_init_fit$lambda), ncol = 3))
estimates_gb_exp_list <- list(sym_ebcovmf_r1_init(R_exp)$v)
for (i in 1:15){
  estimates_gb_exp_list[[(i+1)]] <- sym_ebcovmf_r1_fit(sim_data$YYt, symebcovmf_exp_init_fit, ebnm_fn = ebnm::ebnm_generalized_binary, maxiter = i, tol = 10^(-8))$L_pm[,4]
}
```

```{r}
par(mfrow = c(8,2), mar = c(1.5, 1.5, 1, 1) + 0.1)
for (i in 1:16){
  plot(estimates_gb_exp_list[[i]], main = paste('Iter', (i-1)), ylab = 'L')
}
par(mfrow = c(1,1))
```

### Observations
Using generalized binary for the fourth factor on the point-exponential fit yields an estimate that does not look like a population effect. Similar to other estimates, the factor captures the effect of two populations. Comparing generalized binary and point-exponential for fitting the fourth factor on the point-exponential fit, we see that the point-exponential prior is better at yielding sparse estimates than generalized-binary. The estimate that generalized binary finds is in line with what the prior encourages. Note that since we are using the generalized binary prior, there is nothing constraining the prior to be exactly binary.