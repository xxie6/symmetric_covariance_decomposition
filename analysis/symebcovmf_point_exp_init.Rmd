---
title: "symebcovmf_point_exp_init"
author: "Annie Xie"
date: "2025-04-21"
output: 
  workflowr::wflow_html:
    code_folding: hide
editor_options:
  chunk_output_type: console
---

# Introduction
In this analysis, I want to test out initializing symEBcovMF with the generalized binary prior with symEBcovMF fit with a point-exponential prior.

# Packages and Functions

```{r}
library(ebnm)
library(pheatmap)
library(ggplot2)
```

```{r}
source('code/visualization_functions.R')
source('code/symebcovmf_functions.R')
```

# Example
To test this procedure, I will apply it to the tree-structured dataset. When testing out symEBcovMF, I found that the estimates from the two priors in the tree setting had the largest difference.

## Data Generation

```{r}
sim_4pops <- function(args) {
  set.seed(args$seed)
  
  n <- sum(args$pop_sizes)
  p <- args$n_genes
  
  FF <- matrix(rnorm(7 * p, sd = rep(args$branch_sds, each = p)), ncol = 7)
  # if (args$constrain_F) {
  #   FF_svd <- svd(FF)
  #   FF <- FF_svd$u
  #   FF <- t(t(FF) * branch_sds * sqrt(p))
  # }
  
  LL <- matrix(0, nrow = n, ncol = 7)
  LL[, 1] <- 1
  LL[, 2] <- rep(c(1, 1, 0, 0), times = args$pop_sizes)
  LL[, 3] <- rep(c(0, 0, 1, 1), times = args$pop_sizes)
  LL[, 4] <- rep(c(1, 0, 0, 0), times = args$pop_sizes)
  LL[, 5] <- rep(c(0, 1, 0, 0), times = args$pop_sizes)
  LL[, 6] <- rep(c(0, 0, 1, 0), times = args$pop_sizes)
  LL[, 7] <- rep(c(0, 0, 0, 1), times = args$pop_sizes)
  
  E <- matrix(rnorm(n * p, sd = args$indiv_sd), nrow = n)
  Y <- LL %*% t(FF) + E
  YYt <- (1/p)*tcrossprod(Y)
  return(list(Y = Y, YYt = YYt, LL = LL, FF = FF, K = ncol(LL)))
}
```

```{r}
sim_args = list(pop_sizes = rep(40, 4), n_genes = 1000, branch_sds = rep(2,7), indiv_sd = 1, seed = 1)
sim_data <- sim_4pops(sim_args)
```

This is a heatmap of the scaled Gram matrix:
```{r}
plot_heatmap(sim_data$YYt, colors_range = c('blue','gray96','red'), brks = seq(-max(abs(sim_data$YYt)), max(abs(sim_data$YYt)), length.out = 50))
```

This is a scatter plot of the true loadings matrix:
```{r}
pop_vec <- c(rep('A', 40), rep('B', 40), rep('C', 40), rep('D', 40))
plot_loadings(sim_data$LL, pop_vec)
```

This is a plot of the eigenvalues of the Gram matrix:
```{r}
S_eigen <- eigen(sim_data$YYt)
plot(S_eigen$values) + abline(a = 0, b = 0, col = 'red')
```

This is the minimum eigenvalue:
```{r}
min(S_eigen$values)
```

# Generalized binary symEBcovMF

```{r}
symebcovmf_fit <- sym_ebcovmf_fit(S = sim_data$YYt, ebnm_fn = ebnm::ebnm_generalized_binary, K = 7, maxiter = 500, rank_one_tol = 10^(-8), tol = 10^(-8), refit_lam = TRUE)
```

This is a scatter plot of $\hat{L}$, the estimate from symEBcovMF:
```{r}
bal_pops <- c(rep('A', 40), rep('B', 40), rep('C', 40), rep('D', 40))
plot_loadings(symebcovmf_fit$L_pm %*% diag(sqrt(symebcovmf_fit$lambda)), bal_pops)
```

```{r}
symebcovmf_fit$elbo
```

# Generalized binary symEBcovMF initialized with point-exponential fit
For this procedure, I start by running symEBcovMF with a point-exponential prior with Kmax set to the inputted Kmax value. From this, I get an estimate for $L$, which I call $\hat{L}_{exp}$. Then, I run symEBcovMF with a generalized-binary prior. I initialize the rank-one fit for factor $k$ with the $k$-th column of $\hat{L}_{exp}$.

```{r}
sym_ebcovmf_point_exp_init_full_fit <- function(S, ebnm_fn, Kmax, maxiter, rank_one_tol, tol, refit_lam = FALSE){
  #initialize object
  sym_ebcovmf_obj <- sym_ebcovmf_init(S)
  
  symebcovmf_pexp_gb_fit <- sym_ebcovmf_fit(S, ebnm_fn = ebnm::ebnm_point_exponential, K = Kmax, maxiter = maxiter, rank_one_tol = rank_one_tol, tol = tol, refit_lam = refit_lam)
  
  curr_rank <- 0
  obj_diff <- Inf
  while ((curr_rank < Kmax) & (obj_diff > tol)){
    # add factor
    v_init <- symebcovmf_pexp_gb_fit$L_pm[,(curr_rank+1)]
    sym_ebcovmf_obj <- sym_ebcovmf_r1_fit(S, sym_ebcovmf_obj, ebnm_fn, maxiter, rank_one_tol, v_init = v_init)
    
    # check if new factor was added
    if (length(sym_ebcovmf_obj$vec_elbo_K) == curr_rank){
      print(paste('Adding factor', (curr_rank + 1), 'does not improve the objective function'))
      break
    } else {
      if (curr_rank > 0){
        if (refit_lam == TRUE){
          sym_ebcovmf_obj <- refit_lambda(S, sym_ebcovmf_obj)
        }
        obj_diff <- sym_ebcovmf_obj$vec_elbo_K[curr_rank + 1] - sym_ebcovmf_obj$vec_elbo_K[curr_rank]
      }
    }
    curr_rank <- curr_rank + 1
  }
  
  return(sym_ebcovmf_obj)
}
```

```{r}
symebcovmf_full_pexp_init_fit <- sym_ebcovmf_point_exp_init_full_fit(S = sim_data$YYt, ebnm_fn = ebnm::ebnm_generalized_binary, K = 7, maxiter = 500, rank_one_tol = 10^(-8), tol = 10^(-8), refit_lam = TRUE)
```

This is a scatter plot of $\hat{L}_{exp-init}$, the estimate from symEBcovMF initialized with a point-exponential fit:
```{r}
bal_pops <- c(rep('A', 40), rep('B', 40), rep('C', 40), rep('D', 40))
plot_loadings(symebcovmf_full_pexp_init_fit$L_pm %*% diag(sqrt(symebcovmf_full_pexp_init_fit$lambda)), bal_pops)
```

This is the ELBO:
```{r}
symebcovmf_full_pexp_init_fit$elbo
```

## Comparison
```{r}
ggplot(data = NULL, aes(x = symebcovmf_fit$L_pm[,1], y = symebcovmf_full_pexp_init_fit$L_pm[,1])) + geom_point() + geom_abline(slope = 1, intercept = 0, color = 'red')
```

```{r}
ggplot(data = NULL, aes(x = symebcovmf_fit$L_pm[,2], y = symebcovmf_full_pexp_init_fit$L_pm[,2])) + geom_point() + geom_abline(slope = 1, intercept = 0, color = 'red')
```

```{r}
ggplot(data = NULL, aes(x = symebcovmf_fit$L_pm[,3], y = symebcovmf_full_pexp_init_fit$L_pm[,3])) + geom_point() + geom_abline(slope = 1, intercept = 0, color = 'red')
```

## Observations
We see that the estimate from generalized binary symEBcovMF initialized with the point-exponential fit looks like a tree, unlike the estimate from generalized binary symEBcovMF initialized with SVD. Furthermore, we see that this estimate obtains a higher ELBO than that of the default method. This suggests that the default method may be getting stuck in a local optima. This is not too surprising. I also suspect that the generalized binary prior is very sensitive to initialization, and may struggle to jump to sparser solutions (even if the sparser solutions yield higher objective function values).

I did try a version of this method where I computed the point-exponential fit for each factor within the rank-one fitting procedure. This point-exponential fit used the current residual matrix computed from factors initialized with point-exponential fits and then refit with generalized binary. However, I found that this method did not yield a tree-like loadings estimate. The estimate looked closer to that of regular generalized binary symEBcovMF. In addition, it only yielded a slightly higher ELBO. I've noticed that there are differences in the residual matrices from generalized binary fits vs point-exponential fits. So my best guess for why this occurred is that the residual matrix from the point-exponential fit makes it a little easier to find the group effects one group at a time. Meanwhile, the residual matrix from the generalized binary fit makes it harder to distinguish groups 1 and 4. I explore this more in another analysis. (Perhaps regular power method would also have this issue).
